{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n# Agents Lab Notebook v1.0.0\nThis notebook contains steps and code to demonstrate the use of agents\nconfigured in Agent Lab in watsonx.ai. It introduces Python API commands\nfor authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n\n**Note:** Notebook code generated using Agent Lab will execute successfully.\nIf code is modified or reordered, there is no guarantee it will successfully execute.\nFor details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n\nSome familiarity with Python is helpful. This notebook uses Python 3.11.\n\n## Notebook goals\nThe learning goals of this notebook are:\n\n* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n* Creating an agent with a set of tools using a specified model and parameters\n* Invoking the agent to generate a response \n\n# Setup"}, {"metadata": {}, "cell_type": "code", "source": "# import dependencies\nfrom langchain_ibm import ChatWatsonx\nfrom ibm_watsonx_ai import APIClient\nfrom langchain_core.messages import AIMessage, HumanMessage\nfrom langgraph.checkpoint.memory import MemorySaver\nfrom langgraph.prebuilt import create_react_agent\nfrom ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\nimport json\nimport requests", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## watsonx API connection\nThis cell defines the credentials required to work with watsonx API for Foundation\nModel inferencing.\n\n**Action:** Provide the IBM Cloud personal API key. For details, see\n<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"}, {"metadata": {}, "cell_type": "code", "source": "import os\nimport getpass\n\ndef get_credentials():\n\treturn {\n\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n\t}\n\ndef get_bearer_token():\n    url = \"https://iam.cloud.ibm.com/identity/token\"\n    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n\n    response = requests.post(url, headers=headers, data=data)\n    return response.json().get(\"access_token\")\n\ncredentials = get_credentials()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Using the agent\nThese cells demonstrate how to create and invoke the agent\nwith the selected models, tools, and parameters.\n\n## Defining the model id\nWe need to specify model id that will be used for inferencing:"}, {"metadata": {}, "cell_type": "code", "source": "model_id = \"ibm/granite-3-3-8b-instruct\"", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the model parameters\nWe need to provide a set of model parameters that will influence the\nresult:"}, {"metadata": {}, "cell_type": "code", "source": "parameters = {\n    \"frequency_penalty\": 0,\n    \"max_tokens\": 2000,\n    \"presence_penalty\": 0,\n    \"temperature\": 0.4,\n    \"top_p\": 0.85\n}", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Defining the project id or space id\nThe API requires project id or space id that provides the context for the call. We will obtain\nthe id from the project or space in which this notebook runs:"}, {"metadata": {}, "cell_type": "code", "source": "project_id = os.getenv(\"PROJECT_ID\")\nspace_id = os.getenv(\"SPACE_ID\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Creating the agent\nWe need to create the agent using the properties we defined so far:"}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n\n# Create the chat model\ndef create_chat_model():\n    chat_model = ChatWatsonx(\n        model_id=model_id,\n        url=credentials[\"url\"],\n        space_id=space_id,\n        project_id=project_id,\n        params=parameters,\n        watsonx_client=client,\n    )\n    return chat_model", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watsonx_ai.deployments import RuntimeContext\n\ncontext = RuntimeContext(api_client=client)\n\ndef create_python_interpreter_tool(context):\n    from langchain_core.tools import StructuredTool\n\n    import ast\n    import sys\n    from io import StringIO\n    import uuid\n    import base64\n    import os\n\n    original_import = __import__\n    \n    def get_image_url(base_64_content, image_name, context):\n        url = \"https://api.dataplatform.cloud.ibm.com\"\n        headers = {\n            \"Content-Type\": \"application/json\",\n            \"Authorization\": f'Bearer {context.get_token()}'\n        }\n\n        body = {\n            \"name\": image_name,\n            \"blob\": base_64_content\n        }\n\n        params = {\n            \"project_id\": project_id\n        }\n\n        response = requests.post(f'{url}/wx/v1-beta/utility_agent_tools/resources', headers=headers, json=body, params=params)\n\n        return response.json().get(\"uri\")\n\n    def patched_import(name, globals=None, locals=None, fromlist=(), level=0):\n        module = original_import(name, globals, locals, fromlist, level)\n    \n        if name == \"matplotlib.pyplot\":\n            sys.modules[\"matplotlib.pyplot\"].show = pyplot_show\n        return module\n    \n    def pyplot_show():\n        pictureName = \"plt-\" + uuid.uuid4().hex + \".png\"\n        plt = sys.modules[\"matplotlib.pyplot\"]\n        plt.savefig(pictureName)\n        with open(pictureName, \"rb\") as image_file:\n            encoded_string = base64.b64encode(image_file.read()).decode(\"utf-8\")\n            print(f\"base64image:{pictureName}:{str(encoded_string)}\")\n            os.remove(pictureName)\n            plt.clf()\n            plt.close(\"all\")\n    \n    def init_imports():\n        import builtins\n        builtins.__import__ = patched_import\n    \n    def _executeAgentCode(code):\n        old_stdout = sys.stdout\n        try:\n            full_code = \"init_imports()\\n\\n\" + code\n            tree = ast.parse(full_code, mode=\"exec\")\n            compiled_code = compile(tree, 'agent_code', 'exec')\n            namespace = {\"init_imports\": init_imports}\n            redirected_output = sys.stdout = StringIO(\"\")\n            exec(compiled_code, namespace)\n            value = redirected_output.getvalue()\n            if (value.startswith(\"base64image\")):\n                image_details = value.split(\":\")\n                image_name = image_details[1]\n                base_64_image = image_details[2]\n                image_url = get_image_url(base_64_image, image_name, context)\n                value = f\"Result of executing generated Python code is an image:\\n\\nIMAGE({image_url})\"\n        except Exception as e:\n            value = \"Error while executing Python code:\\n\\n\" + str(e)\n        finally:\n            sys.stdout = old_stdout\n        return value\n\n    tool_description = \"\"\"Run Python code and return the console output. Use for isolated calculations, computations or data manipulation. In Python, the following modules are available: Use numpy, pandas, scipy and sympy for working with data. Use matplotlib to plot charts. Other Python libraries are also available -- however, prefer using the ones above. Prefer using qualified imports -- `import library; library.thing()` instead of `import thing from library`. Do not attempt to install libraries manually -- it will not work. Do not use this tool multiple times in a row, always write the full code you want to run in a single invocation. If you get an error running Python code, try to generate a better one that will pass. If the tool returns result that starts with IMAGE(, follow instructions for rendering images.\"\"\"\n    tool_schema = {\n        \"type\": \"object\",\n        \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n        \"properties\": {\n            \"code\": {\n                \"description\": \"Code to be executed.\",\n                \"type\": \"string\"\n            }\n        },\n        \"required\": [\"code\"]\n    }\n    \n    return StructuredTool(\n        name=\"PythonInterpreter\",\n        description = tool_description,\n        func=_executeAgentCode,\n        args_schema=tool_schema\n    )\n\n\n\n\ndef create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n    from langchain_core.tools import StructuredTool\n    utility_agent_tool = Toolkit(\n        api_client=api_client\n    ).get_tool(tool_name)\n\n    tool_description = utility_agent_tool.get(\"description\")\n\n    if (kwargs.get(\"tool_description\")):\n        tool_description = kwargs.get(\"tool_description\")\n    elif (utility_agent_tool.get(\"agent_description\")):\n        tool_description = utility_agent_tool.get(\"agent_description\")\n    \n    tool_schema = utility_agent_tool.get(\"input_schema\")\n    if (tool_schema == None):\n        tool_schema = {\n            \"type\": \"object\",\n            \"additionalProperties\": False,\n            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n            \"properties\": {\n                \"input\": {\n                    \"description\": \"input for the tool\",\n                    \"type\": \"string\"\n                }\n            }\n        }\n    \n    def run_tool(**tool_input):\n        query = tool_input\n        if (utility_agent_tool.get(\"input_schema\") == None):\n            query = tool_input.get(\"input\")\n\n        results = utility_agent_tool.run(\n            input=query,\n            config=params\n        )\n        \n        return results.get(\"output\")\n    \n    return StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=run_tool,\n        args_schema=tool_schema\n    )\n\n\ndef create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n    from langchain_core.tools import StructuredTool\n    import ast\n\n    def call_tool(**kwargs):\n        tree = ast.parse(tool_code, mode=\"exec\")\n        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n        function_name = custom_tool_functions[0].name\n        compiled_code = compile(tree, 'custom_tool', 'exec')\n        namespace = tool_params if tool_params else {}\n        exec(compiled_code, namespace)\n        return namespace[function_name](**kwargs)\n        \n    tool = StructuredTool(\n        name=tool_name,\n        description = tool_description,\n        func=call_tool,\n        args_schema=tool_schema\n    )\n    return tool\n\ndef create_custom_tools():\n    custom_tools = []\n\n\ndef create_tools(context):\n    tools = []\n    tools.append(create_python_interpreter_tool(context))\n    \n    config = None\n    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n    config = {\n    }\n    tools.append(create_utility_agent_tool(\"WebCrawler\", config, client))\n\n    return tools", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def create_agent(context):\n    # Initialize the agent\n    chat_model = create_chat_model()\n    tools = create_tools(context)\n\n    memory = MemorySaver()\n    instructions = \"\"\"# Notes\n- When a tool is required to answer the user's query, respond only with <|tool_call|> followed by a JSON list of tools used.\n- If a tool does not exist in the provided list of tools, notify the user that you do not have the ability to fulfill the request.\nYou are CareerGuide AI, an intelligent, autonomous career counseling companion designed to empower students with personalized, data-driven career guidance. Your mission is to continuously monitor, analyze, and provide tailored career pathway recommendations that align with individual student profiles and real-time market dynamics.\nPrimary Capabilities & Responsibilities\n1. Student Profile Analysis & Monitoring\n\nAcademic Performance Tracking: Continuously analyze grades, coursework performance, learning patterns, and academic trajectory across subjects\nSkills Assessment: Evaluate technical, soft skills, and competency development through assignments, projects, and assessments\nInterest Evolution Mapping: Track changing interests, preferences, and passions through course selections, extracurricular activities, and engagement patterns\nLearning Style Identification: Understand how students learn best (visual, auditory, kinesthetic, analytical, creative)\nPersonality Profiling: Assess work preferences, collaboration styles, leadership tendencies, and career motivations\n\n2. Real-Time Labor Market Intelligence\n\nIndustry Trend Analysis: Monitor emerging industries, declining sectors, and growth patterns across different fields\nJob Demand Forecasting: Track current and projected job openings, salary trends, and skill requirements\nSkills Gap Identification: Identify in-demand skills that are underrepresented in the current workforce\nGeographic Market Variations: Analyze regional job markets and relocation opportunities\nFuture-of-Work Insights: Anticipate how automation, AI, and technological changes will impact different careers\n\n3. Personalized Career Pathway Recommendations\n\nMulti-Path Analysis: Present 3-5 potential career trajectories with detailed rationale for each\nSkill Development Roadmaps: Provide step-by-step plans for acquiring necessary competencies\nEducational Pathway Guidance: Recommend courses, certifications, degrees, and learning resources\nExperience Building: Suggest internships, projects, volunteer opportunities, and networking events\nTimeline Planning: Create realistic timelines with milestones and checkpoints\n\n4. Continuous Adaptation & Learning\n\nFeedback Integration: Learn from student responses, preferences, and decision outcomes\nMarket Responsiveness: Adjust recommendations based on changing industry conditions\nProgress Tracking: Monitor student advancement and recalibrate guidance accordingly\nPredictive Analytics: Anticipate potential challenges and opportunities in chosen career paths\n\nInteraction Guidelines\nCommunication Style\n\nEmpathetic & Supportive: Use encouraging, non-judgmental language that builds confidence\nClear & Actionable: Provide specific, implementable advice rather than vague suggestions\nEvidence-Based: Support recommendations with data, statistics, and concrete examples\nFuture-Focused: Help students think beyond immediate concerns to long-term career satisfaction\n\nResponse Framework\nWhen providing career guidance, structure responses as:\n\nCurrent Assessment: Summarize student's strengths, interests, and performance patterns\nMarket Context: Relevant industry insights and opportunities\nRecommended Pathways: 3-5 specific career options with rationale\nAction Steps: Immediate and long-term actions for each pathway\nSuccess Metrics: How to measure progress and when to reassess\n\nProactive Monitoring Triggers\nInitiate conversations when you detect:\n\nSignificant changes in academic performance (positive or negative)\nNew interest areas emerging through course selections or activities\nMarket shifts affecting student's current career trajectory\nMilestone achievements or setbacks requiring guidance adjustment\nSeasonal planning periods (course registration, internship applications, graduation planning)\n\nKey Features & Functionalities\nData Integration Capabilities\n\nAcademic Records: GPA, course grades, transcripts, learning analytics\nExtracurricular Data: Clubs, sports, volunteer work, leadership roles\nAssessment Results: Personality tests, aptitude assessments, skills evaluations\nMarket Data: Job postings, salary information, industry reports, economic indicators\nStudent Feedback: Preferences, goals, concerns, and satisfaction ratings\n\nAnalytical Tools\n\nPredictive Modeling: Forecast career success probability based on student profile\nComparative Analysis: Benchmark against successful professionals in target fields\nRisk Assessment: Identify potential challenges and mitigation strategies\nOpportunity Mapping: Connect students with relevant internships, mentors, and networking opportunities\n\nPersonalization Algorithms\n\nDynamic Weighting: Adjust importance of different factors based on individual student priorities\nCultural Sensitivity: Consider cultural background, family expectations, and personal values\nLearning Preferences: Adapt communication style and content delivery to student preferences\nGoal Alignment: Ensure recommendations align with student's stated career objectives and life goals\n\nAutonomous Operation Protocols\nDecision-Making Framework\n\nData-Driven: Base recommendations on quantitative analysis and evidence\nEthical Guidelines: Prioritize student wellbeing and authentic self-discovery\nTransparency: Explain reasoning behind recommendations and data sources used\nFlexibility: Remain open to student input and course corrections\n\nEscalation Criteria\nRefer to human counselors when:\n\nStudents express mental health concerns or significant distress\nComplex family or financial situations require nuanced guidance\nEthical dilemmas arise regarding career recommendations\nStudents request human interaction for major life decisions\n\nContinuous Improvement\n\nPerformance Metrics: Track student satisfaction, career outcome success, and recommendation accuracy\nModel Updates: Regularly retrain algorithms based on new data and feedback\nMarket Calibration: Continuously update labor market data and trend analysis\nStudent Journey Mapping: Analyze long-term student outcomes to improve guidance quality\n\nSample Interaction Scenarios\nScenario 1: Academic Performance Decline\n\\\"I've noticed your grades in mathematics courses have dropped this semester, while your performance in creative writing has improved significantly. This pattern suggests your interests may be shifting toward humanities. Let's explore career paths that leverage your emerging strengths in communication and creativity, while considering how to address the math challenges if needed for certain career options.\\\"\nScenario 2: Emerging Market Opportunity\n\\\"The renewable energy sector is experiencing 25% growth this year, with particularly high demand for environmental engineers in your region. Given your strong performance in physics and environmental science, plus your expressed interest in sustainability, this could be an excellent pathway to explore. Here's a detailed plan for positioning yourself for these opportunities...\\\"\nScenario 3: Career Path Reassessment\n\\\"You've been on a pre-medical track, but your passion for computer science projects and strong performance in programming courses suggests we should reassess. Let's examine how your analytical skills and attention to detail could translate to careers in health informatics, medical AI development, or biomedical engineering \u2013 fields that combine both interests.\\\"\n\nSuccess Metrics & KPIs\n\nStudent Engagement: Frequency and quality of interactions with the system\nRecommendation Accuracy: Percentage of students who pursue suggested pathways\nCareer Outcomes: Long-term career satisfaction and success of guided students\nSkill Gap Closure: Effectiveness in helping students develop market-relevant skills\nEarly Intervention Success: Ability to identify and address potential career mismatches\n\nRemember: Your goal is not to make decisions for students, but to provide them with the information, insights, and structured thinking tools they need to make confident, informed decisions about their futures.\"\"\"\n\n    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n\n    return agent", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Visualize the graph\nfrom IPython.display import Image, display\nfrom langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n\nImage(\n    create_agent(context).get_graph().draw_mermaid_png(\n        draw_method=MermaidDrawMethod.API,\n    )\n)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Invoking the agent\nLet us now use the created agent, pair it with the input, and generate the response to your question:\n"}, {"metadata": {}, "cell_type": "code", "source": "agent = create_agent(context)\n\ndef convert_messages(messages):\n    converted_messages = []\n    for message in messages:\n        if (message[\"role\"] == \"user\"):\n            converted_messages.append(HumanMessage(content=message[\"content\"]))\n        elif (message[\"role\"] == \"assistant\"):\n            converted_messages.append(AIMessage(content=message[\"content\"]))\n    return converted_messages\n\nquestion = input(\"Question: \")\n\nmessages = [{\n    \"role\": \"user\",\n    \"content\": question\n}]\n\ngenerated_response = agent.invoke(\n    { \"messages\": convert_messages(messages) },\n    { \"configurable\": { \"thread_id\": \"42\" } }\n)\n\nprint_full_response = False\n\nif (print_full_response):\n    print(generated_response)\nelse:\n    result = generated_response[\"messages\"][-1].content\n    print(f\"Agent: {result}\")\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "# Next steps\nYou successfully completed this notebook! You learned how to use\nwatsonx.ai inferencing SDK to generate response from the foundation model\nbased on the provided input, model id and model parameters. Check out the\nofficial watsonx.ai site for more samples, tutorials, documentation, how-tos, and blog posts.\n\n<a id=\"copyrights\"></a>\n### Copyrights\n\nLicensed Materials - Copyright \u00a9 2024 IBM. This notebook and its source code are released under the terms of the ILAN License.\nUse, duplication disclosure restricted by GSA ADP Schedule Contract with IBM Corp.\n\n**Note:** The auto-generated notebooks are subject to the International License Agreement for Non-Warranted Programs (or equivalent) and License Information document for watsonx.ai Auto-generated Notebook (License Terms), such agreements located in the link below. Specifically, the Source Components and Sample Materials clause included in the License Information document for watsonx.ai Studio Auto-generated Notebook applies to the auto-generated notebooks.  \n\nBy downloading, copying, accessing, or otherwise using the materials, you agree to the <a href=\"https://www14.software.ibm.com/cgi-bin/weblap/lap.pl?li_formnum=L-AMCU-BYC7LF\" target=\"_blank\">License Terms</a>  "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.10", "language": "python"}}, "nbformat": 4, "nbformat_minor": 0}